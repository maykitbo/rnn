0.69259393215179440.69347155094146730.69340294599533080.69319546222686770.69319236278533940.69333964586257930.6932460665702820.69324034452438350.6932601332664490.69314080476760860.69317078590393070.69317889213562010.693151056766510.69314014911651610.69311797618865970.69310772418975830.69309949874877930.69310820102691650.69311690330505370.69308960437774660.6930910944938660.69308662414550780.69304406642913820.69303756952285770.69300657510757450.69298589229583740.6929960846900940.69303971529006960.69300568103790280.69293463230133060.69291120767593380.69290840625762940.69290500879287720.69285422563552860.69283068180084230.69287568330764770.69281858205795290.69277781248092650.69278866052627560.6928275823593140.6928395032882690.69279754161834720.69276213645935060.69272047281265260.69269204139709470.69260722398757930.69253003597259520.6925136446952820.69238579273223880.69235008955001830.69227629899978640.69220691919326780.69217044115066530.69204509258270260.69209659099578860.69210010766983030.69216406345367430.69208520650863650.6920423507690430.69190555810928340.69180071353912350.69171422719955440.6915970444679260.69147515296936040.69131332635879520.69113457202911380.69098067283630370.69069230556488040.69061249494552610.69027632474899290.68994677066802980.68945562839508060.68881267309188840.68820768594741820.68756121397018430.68686693906784060.68576568365097050.6840098500251770.68295508623123170.67979156970977780.6825155615806580.68060284852981570.67912000417709350.67708557844161990.6759685873985290.67477238178253170.67344576120376590.67149990797042850.66938102245330810.66838079690933230.66690427064895630.66526776552200320.66414135694503780.66275191307067870.66103667020797730.65904855728149410.65720015764236450.65537208318710330.65353232622146610.65171927213668820.65000951290130620.64839899539947510.64654308557510380.64508759975433350.64386886358261110.64294767379760740.64086186885833740.63903659582138060.63690817356109620.63560163974761960.63309854269027710.63126343488693240.62910759449005130.62772464752197270.62593901157379150.62415713071823120.62185174226760860.62009996175765990.61773544549942020.61635839939117430.61457347869873050.61300742626190190.61045163869857790.60886603593826290.60768091678619380.60616117715835570.60470271110534670.60324060916900630.60082226991653440.59874403476715090.59762036800384520.59534263610839840.59351450204849240.59201717376708980.59097319841384890.58934563398361210.58805316686630250.58601176738739010.58524852991104130.58362352848052980.58178508281707760.58020538091659550.57896083593368530.57776427268981930.5761514306068420.57491463422775270.57305479049682620.57153624296188350.57078838348388670.56927561759948730.56827694177627560.56707328557968140.56545495986938480.56405156850814820.56255239248275760.56146466732025150.561312735080719
Epoch: 0, Training Loss: 0.561312735080719, Training Accuracy: 0.6811000108718872, Validation Loss: 0.3527297079563141, Validation Accuracy: 0.848800003528595
0.333235323429107670.28098309040069580.28419011831283570.299580812454223630.31193619966506960.320284515619277950.316824138164520260.31205919384956360.3115026056766510.31142967939376830.310544133186340330.304460674524307250.301875144243240360.297626197338104250.300114065408706670.294337093830108640.29542830586433410.291711151599884030.28992015123367310.289957582950592040.29308238625526430.29083099961280820.288648247718811040.290045946836471560.290579825639724730.29129397869110110.290961027145385740.28974360227584840.29235041141510010.290210932493209840.2946709692478180.29319277405738830.293757021427154540.293575137853622440.29447692632675170.29477655887603760.29354569315910340.293387353420257570.291605234146118160.290190786123275760.291072130203247070.289654552936553960.288258522748947140.287190139293670650.284132540225982670.282892286777496340.28220990300178530.281766057014465330.282933890819549560.28269979357719420.28171405196189880.28144904971122740.28291177749633790.282645642757415770.28234574198722840.28150865435600280.28197559714317320.28095886111259460.28070801496505740.27835953235626220.27769470214843750.27719497680664060.277505129575729370.27658131718635560.276967197656631470.277639329433441160.277747154235839840.278920590877532960.28059971332550050.280568122863769530.280323475599288940.280931353569030760.281974315643310550.28141343593597410.28210285305976870.28236898779869080.282069981098175050.28206640481948850.28229942917823790.28168570995330810.28124994039535520.280766487121582030.280920743942260740.280148804187774660.281184971332550050.280928492546081540.28085538744926450.27940994501113890.27896431088447570.279594659805297850.27932903170585630.27944487333297730.27954781055450440.278886467218399050.279905170202255250.27987721562385560.279669046401977540.27892878651618960.2780770957469940.277736693620681760.27756729722023010.27801507711410520.27805286645889280.277810841798782350.276930630207061770.27714413404464720.277470737695693970.276979833841323850.27696305513381960.276923626661300660.276415258646011350.27687090635299680.27773854136466980.2781366705894470.277397364377975460.277510046958923340.27721148729324340.27688595652580260.27695277333259580.276411384344100950.27635315060615540.27628871798515320.27575370669364930.27586489915847780.27550834417343140.27504965662956240.27472940087318420.27374994754791260.27352353930473330.27357816696166990.273394972085952760.273614138364791870.273725807666778560.27410402894020080.27366220951080320.27332946658134460.273218154907226560.272932618856430050.27291390299797060.27267482876777650.27246308326721190.2719731926918030.271622270345687870.27139329910278320.271468222141265870.27252799272537230.27177083492279050.271718263626098630.27137410640716550.271412342786788940.271529287099838260.27093678712844850.270657896995544430.270580798387527470.27098980545997620.271293431520462040.27131327986717224
Epoch: 1, Training Loss: 0.27131327986717224, Training Accuracy: 0.8999000191688538, Validation Loss: 0.29563289880752563, Validation Accuracy: 0.876800000667572
0.17622980475425720.18095785379409790.191021725535392760.178357496857643130.170905739068984990.17432582378387450.181018456816673280.180639982223510740.183925047516822810.188731521368026730.187570527195930480.19008505344390870.18722656369209290.192748636007308960.191534996032714840.1880585402250290.188815802335739140.190770879387855530.194152534008026120.193599224090576170.194030210375785830.195158615708351140.195146709680557250.19693939387798310.19943040609359740.198583364486694340.19991485774517060.202086135745048520.203221037983894350.201409041881561280.201570197939872740.199076190590858460.197622537612915040.196089401841163640.19668067991733550.194778338074684140.195796281099319460.196771442890167240.19666518270969390.19656659662723540.19715420901775360.200430557131767270.200300723314285280.200154542922973630.198659360408782960.20004659891128540.19953289628028870.200128898024559020.199299752712249760.19823372364044190.19721741974353790.195703759789466860.194636374711990360.19277781248092650.19296920299530030.19243438541889190.19201561808586120.1915104091167450.19211420416831970.19296653568744660.19297134876251220.192890107631683350.192093282938003540.19201634824275970.192217692732810970.191264972090721130.1911359727382660.190917059779167180.190246060490608220.189389243721961980.188933178782463070.18912859261035920.190058678388595580.189669951796531680.189131423830986020.18809609115123750.187445819377899170.187168493866920470.18913197517395020.188478916883468630.187558218836784360.187043055891990660.187084048986434940.187099516391754150.18726097047328950.187288910150527950.186988815665245060.186240345239639280.186033308506011960.18620206415653230.186889737844467160.186394751071929930.18618895113468170.186163842678070070.186564281582832340.18785361945629120.188187211751937870.18776376545429230.188275635242462160.188067376613616940.188308998942375180.188170775771141050.187812641263008120.187202617526054380.188350573182106020.188793703913688660.188485801219940190.188207760453224180.18823462724685670.18820771574974060.18899804353713990.189332172274589540.189406767487525940.18882995843887330.188681036233901980.189119920134544370.189423471689224240.18930174410343170.18882898986339570.188843831419944760.1892870068550110.189377501606941220.18974858522415160.190629541873931880.191708400845527650.192168310284614560.192302733659744260.192578226327896120.192213431000709530.19190981984138490.1920180618762970.191519677639007570.191657543182373050.192153751850128170.191798955202102660.191606134176254270.191326856613159180.19124954938888550.191266939043998720.19141812622547150.191031754016876220.191258952021598820.191565975546836850.191532492637634280.19158813357353210.191076546907424930.190909639000892640.19124685227870940.19116988778114320.19159156084060670.191827118396759030.19222515821456910.192160144448280330.192363962531089780.19252884387969970.192861244082450870.19288483262062073
Epoch: 2, Training Loss: 0.19288483262062073, Training Accuracy: 0.9351000189781189, Validation Loss: 0.3043043315410614, Validation Accuracy: 0.879800021648407
0.154663518071174620.158100545406341550.140937149524688720.13081264495849610.143398270010948180.155695170164108280.155337452888488770.15062122046947480.14630512893199920.148368090391159060.147408708930015560.145090594887733460.145762965083122250.148039609193801880.146928951144218440.147329017519950870.144674003124237060.147385060787200930.149045974016189580.1490745246410370.14585486054420470.14452493190765380.145600199699401860.145198658108711240.142879068851470950.145740896463394170.146024122834205630.144679084420204160.142693936824798580.143838927149772640.144689127802848820.144655629992485050.14468866586685180.144246742129325870.14694482088088990.148446768522262570.14782278239727020.14761911332607270.149154841899871830.149529784917831420.149218887090682980.148024201393127440.147351413965225220.146362647414207460.147204786539077760.14679174125194550.146490260958671570.145524725317955020.145092174410820.145283132791519170.147324755787849430.145856961607933040.144921764731407170.14349049329757690.143906265497207640.143589377403259280.144580721855163570.14467801153659820.143976956605911250.145704910159111020.145303696393966670.14599587023258210.14632233977317810.145900249481201170.146319091320037840.146510884165763850.148194909095764160.148886710405349730.15008641779422760.15052090585231780.150972738862037660.151168525218963620.15141777694225310.15133471786975860.150491937994956970.150560542941093440.15084981918334960.150928914546966550.150566756725311280.149507269263267520.149316206574440.149587571620941160.149709880352020260.14924570918083190.14831569790840150.14899580180644990.14965069293975830.149329662322998050.149779140949249270.149493798613548280.149471133947372440.148809894919395450.149290576577186580.149942621588706970.150284901261329650.149559825658798220.149813845753669740.149250522255897520.149121999740600590.149678826332092290.149745449423789980.149427980184555050.148935899138450620.14953295886516570.149934634566307070.150277674198150630.150897622108459470.151926249265670780.152038991451263430.151986122131347660.151642695069313050.151923328638076780.151903241872787480.151143193244934080.15076339244842530.150970309972763060.151106759905815120.151550129055976870.15128847956657410.151386767625808720.151705145835876460.151679724454879760.15151444077491760.15168520808219910.151450425386428830.151468560099601750.151432275772094730.151168987154960630.151129439473152160.151344567537307740.151229321956634520.151300996541976930.150841534137725830.150947347283363340.15054225921630860.150421291589736940.150796666741371150.150193631649017330.150667801499366760.150862544775009160.151050493121147160.151362448930740360.150890424847602840.150722771883010860.150536999106407170.150063335895538330.14964872598648070.149946019053459170.14989867806434630.15036153793334960.149855524301528930.149433985352516170.14940077066421510.149888843297958370.150099381804466250.150442779064178470.15051552653312683
Epoch: 3, Training Loss: 0.15051552653312683, Training Accuracy: 0.9548500180244446, Validation Loss: 0.33617258071899414, Validation Accuracy: 0.8755999803543091
0.111367627978324890.111657589673995970.111950121819972990.109034977853298190.100115776062011720.111909918487071990.117190845310688020.112452127039432530.109547570347785950.118182934820652010.123026616871356960.121406532824039460.121126480400562290.119134403765201570.120998017489910130.122838653624057770.119108870625495910.121295094490051270.121083483099937440.121757984161376950.123275235295295720.120811730623245240.119839824736118320.119365930557250980.118235826492309570.121562533080577850.119863145053386690.117467872798442840.115384705364704130.118212319910526280.119192615151405330.117372892796993260.115785457193851470.114832021296024320.115828052163124080.115404993295669560.114440336823463440.11342534422874450.113196127116680150.112936154007911680.113385118544101720.115123547613620760.114994183182716370.114915534853935240.114545464515686040.114084340631961820.11410087347030640.114937238395214080.115120150148868560.115225389599800110.115886427462100980.11492412537336350.115421779453754430.117647789418697360.117957413196563720.118419930338859560.118382021784782410.118006311357021330.118503250181674960.117460183799266820.118623927235603330.118272386491298680.120246186852455140.120420455932617190.119986325502395630.119960509240627290.121186241507530210.120521515607833860.120800420641899110.120440021157264710.120096310973167420.120727688074111940.12081059813499450.122336424887180330.122474007308483120.122288204729557040.123634152114391330.122878037393093110.123222775757312770.12241667509078980.12245371192693710.12193443626165390.121878162026405330.122334279119968410.121545709669590.12148056179285050.120777107775211330.120826572179794310.120978623628616330.120666310191154480.121055521070957180.120562210679054260.120189636945724490.120118446648120880.120557934045791630.121354460716247560.1213296651840210.120808854699134830.120715476572513580.12030975520610810.120027512311935420.119933232665061950.120203584432601930.120825573801994320.12075515091419220.120106838643550870.119897425174713130.120225757360458370.119516238570213320.119442567229270940.119634985923767090.119460709393024440.118904799222946170.11843870580196380.11815123260021210.118429720401763920.1185259297490120.118482008576393130.118173822760581970.118116751313209530.11847045272588730.118796803057193760.119599640369415280.119772493839263920.119794845581054690.119928352534770970.12019903957843780.119937248528003690.119835428893566130.119827479124069210.11967009305953980.119330793619155880.119165718555450440.119163446128368380.119544245302677150.1193266510963440.119456090033054350.119477413594722750.119864843785762790.120579950511455540.120868861675262450.121309936046600340.121045969426631930.120851889252662660.120410799980163570.120234020054340360.120218001306056980.120223306119441990.120392933487892150.120042800903320310.120448559522628780.120533481240272520.120245106518268590.120820872485637660.121026940643787380.121592640876770020.12196718901395798
Epoch: 4, Training Loss: 0.12196718901395798, Training Accuracy: 0.9652000069618225, Validation Loss: 0.3521381616592407, Validation Accuracy: 0.8758000135421753
0.089640513062477110.115306891500949860.101320348680019380.101365029811859130.088904052972793580.094984196126461030.08828274160623550.102422408759593960.108512826263904570.102302528917789460.099429376423358920.100966632366180420.096301481127738950.096417345106601720.09659878909587860.096883974969387050.096475064754486080.094714432954788210.094949513673782350.099199876189231870.099698677659034730.101573519408702850.09881808608770370.103446274995803830.10304648429155350.105210527777671810.103255622088909150.102305985987186430.101360097527503970.101283647119998930.10069445520639420.101752102375030520.100208789110183720.09975977987051010.100087404251098630.099380128085613250.099724546074867250.098936215043067930.100366130471229550.100630879402160640.099516667425632480.099652506411075590.09832691401243210.097024507820606230.098736360669136050.099811315536499020.099265269935131070.098802030086517330.097654692828655240.097615852952003480.096534512937068940.096859447658061980.096560493111610410.096428923308849330.096907727420330050.097185336053371430.096674181520938870.096470780670642850.097714260220527650.097825862467288970.097607351839542390.097154110670089720.097105026245117190.098512753844261170.09872873872518540.098238311707973480.097979858517646790.097560741007328030.097193829715251920.097244791686534880.098933212459087370.099144376814365390.098916344344615940.098304599523544310.098183609545230870.09799122065305710.098169997334480290.097261987626552580.096903756260871890.097132489085197450.096861638128757480.097196273505687710.096863701939582820.096818074584007260.097117982804775240.09793043881654740.097572468221187590.098538748919963840.09797934442758560.097739927470684050.097590319812297820.097306825220584870.098786242306232450.098129890859127040.097978092730045320.098702244460582730.098726004362106320.098273210227489470.09890165925025940.098336488008499150.098716065287590030.098696865141391750.098675340414047240.09914363175630570.099088095128536220.098744668066501620.09900191426277160.098620831966400150.098207533359527590.098471768200397490.098456665873527530.099141784012317660.098738782107830050.098329268395900730.09803092479705810.098034374415874480.097888372838497160.098100163042545320.097883142530918120.098271079361438750.098340295255184170.098811872303485870.099674150347709660.099860429763793950.099945776164531710.100125409662723540.09993127733469010.099919244647026060.099912300705909730.100721523165702820.100349761545658110.100303508341312410.100400187075138090.100491374731063840.100177302956581120.099659368395805360.099412925541400910.100608758628368380.100371748208999630.099924117326736450.09977187961339950.099261693656444550.100204639136791230.100497670471668240.100643858313560490.10047814249992370.10052489489316940.101285107433795930.101161919534206390.100975617766380310.101094909012317660.101483844220638280.10148110985755920.101678580045700070.102137789130210880.102167204022407530.10204429179430008
Epoch: 5, Training Loss: 0.10204429179430008, Training Accuracy: 0.9732000231742859, Validation Loss: 0.3804680109024048, Validation Accuracy: 0.870199978351593

Training finished.
Final Training Loss: 0.10204429179430008, Final Training Accuracy: 0.9732000231742859, Final Validation Loss: 0.3804680109024048, Final Validation Accuracy: 0.870199978351593
Time taken: 354.36482524871826
