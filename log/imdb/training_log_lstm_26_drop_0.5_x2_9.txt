0.69247931241989140.69256806373596190.69278198480606080.69284188747406010.69299870729446410.69324040412902830.69326561689376830.69318187236785890.69309061765670780.69312655925750730.69308018684387210.69303488731384280.69308507442474370.69313287734985350.69321841001510620.69325101375579830.69317525625228880.69317436218261720.69320446252822880.69316673278808590.69313186407089230.69314360618591310.69314366579055790.6931287646293640.69315576553344730.69313633441925050.69315111637115480.69313019514083860.69310373067855830.69307297468185420.69303447008132930.69299232959747310.69297647476196290.69293391704559330.69290673732757570.6928780078887940.69282972812652590.69281738996505740.69273936748504640.69268125295639040.6926065087318420.69258224964141850.69253599643707280.69252115488052370.69247573614120480.69239866733551030.69237834215164180.69245749711990360.69244098663330080.69228577613830570.69216793775558470.69211727380752560.69193053245544430.69188433885574340.69192010164260860.69188553094863890.69184178113937380.69178926944732670.69168460369110110.69146168231964110.69142013788223270.69130504131317140.69111907482147220.69098204374313350.69090521335601810.69068139791488650.69037866592407230.69020515680313110.68998056650161740.68965709209442140.689158558845520.68872195482254030.68806916475296020.68724876642227170.68656182289123540.68524599075317380.6850052475929260.68385463953018190.6827862262725830.6818677783012390.6811693310737610.68013232946395870.67934620380401610.6785230636596680.67711830139160160.67638880014419560.67476201057434080.67425978183746340.67332160472869870.67202883958816530.67125993967056270.67008775472640990.66877526044845580.66743940114974980.66572415828704830.66376572847366330.66149204969406130.66019344329833980.65824031829833980.65735429525375370.65568220615386960.65405005216598510.65245562791824340.650721013545990.64912539720535280.64715403318405150.64537841081619260.6441162228584290.64305841922760010.6408346295356750.63923704624176030.63802719116210940.63632208108901980.63454163074493410.63297075033187870.63171535730361940.6300319433212280.62820285558700560.62653148174285890.62509703636169430.62282854318618770.62087815999984740.62007999420166020.61864984035491940.61726325750350950.61575305461883540.61446166038513180.6133539676666260.61208570003509520.61086070537567140.60901832580566410.60776323080062870.60626029968261720.60532408952713010.60410034656524660.60300141572952270.60171467065811160.60052984952926640.59968894720077510.59816396236419680.5967876911163330.59540331363677980.59411412477493290.59189397096633910.59038579463958740.58916646242141720.58797472715377810.58695292472839360.58501648902893070.58367037773132320.58273810148239140.58082908391952510.57929682731628420.57832556962966920.57701492309570310.57585579156875610.5755138397216797
Epoch: 0, Training Loss: 0.5755138397216797, Training Accuracy: 0.6675500273704529, Validation Loss: 0.375334769487381, Validation Accuracy: 0.8399999737739563
0.446894168853759770.364991337060928340.3354777395725250.328760862350463870.32215952873229980.32736930251121520.32050243020057680.321574240922927860.317046970129013060.31294974684715270.308015733957290650.310595691204071040.307804048061370850.306126534938812260.304474949836730960.30858433246612550.30868554115295410.303797066211700440.30148848891258240.300009906291961670.30083718895912170.30198109149932860.30740022659301760.30798408389091490.30599924921989440.306063145399093630.303595483303070070.30177381634712220.300561189651489260.29919388890266420.29890903830528260.298687756061553960.298670560121536250.29754322767257690.29890519380569460.29930937290191650.301922887563705440.301564693450927730.300332278013229370.3002386987209320.29991126060485840.300158441066741940.300099283456802370.301501214504241940.302186429500579830.300904393196105960.30311560630798340.30229866504669190.30204382538795470.3016909360885620.301147580146789550.302446275949478150.301865994930267330.301060408353805540.300286799669265750.299868494272232060.30040368437767030.300443232059478760.29988265037536620.301531761884689330.30110001564025880.301739782094955440.300732970237731930.300635367631912230.300511568784713750.300390452146530150.2991769611835480.298632293939590450.29976278543472290.300511777400970460.29924008250236510.30042865872383120.299713224172592160.299161255359649660.299649268388748170.300124049186706540.299331516027450560.29904735088348390.299495548009872440.29883468151092530.29743379354476930.29727730154991150.297042280435562130.29708060622215270.29734879732131960.29747542738914490.2976045012474060.29834136366844180.29883074760437010.298117905855178830.29877871274948120.298355698585510250.29800993204116820.29766863584518430.296948522329330440.29655313491821290.296846807003021240.297054111957550050.29638135433197020.29695329070091250.297628909349441530.29755073785781860.297368496656417850.2972984015941620.296766400337219240.29673036932945250.29668149352073670.2963092327117920.29599359631538390.295334249734878540.29475161433219910.29483613371849060.29466900229454040.29498121142387390.294560641050338750.29460480809211730.294485062360763550.29381787776947020.29310002923011780.293320775032043460.29463630914688110.29450836777687070.295023471117019650.294495671987533570.29481646418571470.29475021362304690.294532001018524170.294445306062698360.294487506151199340.29458978772163390.29456120729446410.29469570517539980.29447743296623230.29437103867530820.294037729501724240.293717563152313230.293472945690155030.29337802529335020.29328992962837220.29321646690368650.29310604929924010.29340156912803650.29309663176536560.292779684066772460.29311534762382510.292964965105056760.293341845273971560.292968899011611940.29282057285308840.29285073280334470.29290390014648440.29216870665550230.29222276806831360.291999608278274540.29171219468116760.2916893959045410.2918522357940674
Epoch: 1, Training Loss: 0.2918522357940674, Training Accuracy: 0.8924000263214111, Validation Loss: 0.2928698658943176, Validation Accuracy: 0.8805999755859375
0.165083497762680050.193389773368835450.201622173190116880.227604836225509640.225813463330268860.2286343127489090.219785347580909730.222776830196380620.226466044783592220.22730536758899690.228806436061859130.226358637213706970.227203980088233950.22139337658882140.217175722122192380.21307133138179780.211181968450546260.20824709534645080.211824998259544370.211863353848457340.209417507052421570.206796690821647640.205890610814094540.206329390406608580.20543825626373290.20451624691486360.2049754261970520.202838435769081120.201882451772689820.203264698386192320.20073783397674560.20212520658969880.201461628079414370.20281668007373810.202654570341110230.202246129512786870.203369542956352230.203952684998512270.203829675912857060.203402429819107060.203584909439086910.20218889415264130.202399164438247680.20169888436794280.20141845941543580.202090382575988770.20089240372180940.202170923352241520.20238749682903290.201377823948860170.200553387403488160.19953897595405580.198013022541999820.198914662003517150.19920128583908080.200171902775764470.199872538447380070.200335830450057980.201100975275039670.20142760872840880.202148571610450740.201941475272178650.200931191444396970.202179476618766780.201518893241882320.203036516904830930.203172057867050170.202340945601463320.202161446213722230.201197132468223570.201488792896270750.200519070029258730.200785428285598750.199900388717651370.199497804045677190.200415655970573430.200572490692138670.200133621692657470.199737012386322020.199371248483657840.199119314551353450.198435366153717040.199022725224494930.19988819956779480.2002781778573990.200345575809478760.200384184718132020.200269073247909550.201200738549232480.201147124171257020.201580509543418880.202234804630279540.20217268168926240.201249301433563230.20077466964721680.201825276017189030.201302230358123780.201510623097419740.202037349343299870.2024104893207550.202393710613250730.20332507789134980.203242510557174680.203339174389839170.203175038099288940.203302711248397830.203276216983795170.20428684353828430.204884245991706850.205092847347259520.204940199851989750.2045791596174240.20402236282825470.20451110601425170.205000087618827820.205290704965591430.205227956175804140.205189019441604610.20627969503402710.20617605745792390.206189498305320740.206448867917060850.205982476472854610.205884516239166260.206175878643989560.206212550401687620.206006124615669250.206650808453559880.207159414887428280.20689660310745240.206333637237548830.20630608499050140.206483960151672360.206158041954040530.206139355897903440.206195712089538570.205939784646034240.20543296635150910.20543298125267030.2055523395538330.20540487766265870.20570202171802520.205458983778953550.205458819866180420.205473676323890690.205763190984725950.20618236064910890.206712797284126280.206387430429458620.206181481480598450.206602513790130620.206803426146507260.207304567098617550.207685828208923340.20786489546298980.207402125000953670.20742502808570862
Epoch: 2, Training Loss: 0.20742502808570862, Training Accuracy: 0.9302999973297119, Validation Loss: 0.2893369495868683, Validation Accuracy: 0.8866000175476074
0.198856502771377560.183611586689949040.198211237788200380.20946006476879120.207611709833145140.20506285130977630.199127331376075740.19847132265567780.195989772677421570.19012670218944550.185001045465469360.189052328467369080.184445470571517940.180540338158607480.17317396402359010.170588284730911250.171393856406211850.171539455652236940.167929351329803470.167267367243766780.172461017966270450.17074149847030640.172100633382797240.173196867108345030.174307629466056820.178488716483116150.177316486835479740.178082063794136050.179250985383987430.176209375262260440.17540439963340760.173480421304702760.17310342192649840.171748906373977660.169755309820175170.166796654462814330.16547888517379760.164503857493400570.164263337850570680.163807570934295650.163324102759361270.162999331951141360.163273498415946960.16463576257228850.163265988230705260.161595031619071960.162355318665504460.162016704678535460.162169098854064940.162429139018058780.161671042442321780.162090092897415160.16089108586311340.1615034043788910.161547854542732240.160491034388542180.16037254035472870.160793334245681760.16035628318786620.160956904292106630.161515906453132630.160831719636917110.161006942391395570.159876450896263120.159576073288917540.15916372835636140.159537822008132930.160427883267402650.159390032291412350.159884378314018250.160412862896919250.160400927066802980.15944029390811920.159714654088020320.160090491175651550.160252228379249570.16077822446823120.160243868827819820.160931736230850220.16118559241294860.160664305090904240.160177454352378850.161135092377662660.160946220159530640.160746932029724120.160812795162200930.160018756985664370.160280361771583560.160103052854537960.160388156771659850.159998163580894470.159637019038200380.15971834957599640.15966653823852540.159303501248359680.159419640898704530.15966457128524780.15994432568550110.160608038306236270.16039285063743590.160318240523338320.160453528165817260.16066366434097290.16061498224735260.161035060882568360.161109387874603270.16142927110195160.16133555769920350.161742523312568660.162000209093093870.161618635058403020.161066025495529170.16074286401271820.160505115985870360.160589858889579770.160221531987190250.160437092185020450.160525009036064150.160345599055290220.16018897294998170.160402506589889530.161119163036346440.160899460315704350.16101682186126710.160617217421531680.160565406084060670.160592854022979740.16073513031005860.160294905304908750.160543918609619140.16057451069355010.160636156797409060.16094461083412170.16057452559471130.16052149236202240.16078449785709380.161886647343635560.16157871484756470.161555051803588870.161456838250160220.161492854356765750.161922469735145570.161871835589408870.161813005805015560.162079453468322750.16200907528400420.16174919903278350.161553621292114260.161349058151245120.160865038633346560.161103099584579470.161359697580337520.16161744296550750.162025198340415950.16246370971202850.16245548427104950.1624646633863449
Epoch: 3, Training Loss: 0.1624646633863449, Training Accuracy: 0.9498000144958496, Validation Loss: 0.3104366362094879, Validation Accuracy: 0.8844000101089478
0.090079382061958310.095967590808868410.104578971862792970.105268672108650210.133395373821258540.131284311413764950.1357223540544510.131052345037460330.131106078624725340.130652472376823430.131550461053848270.135817661881446840.133389949798583980.13309128582477570.13786850869655610.13602578639984130.131473913788795470.12972222268581390.130547523498535160.1290762871503830.129407912492752080.129816487431526180.133692309260368350.132927373051643370.133468329906463620.137626186013221740.137433543801307680.137819483876228330.140626877546310420.14216810464859010.14420329034328460.14237904548645020.140556797385215760.139944508671760560.140198931097984310.14012728631496430.13855588436126710.139073014259338380.137801498174667360.137179329991340640.137485682964324950.137474030256271360.135491907596588130.134073004126548770.134976729750633240.134448170661926270.134511426091194150.13304623961448670.133686244487762450.13434395194053650.13491722941398620.137408405542373660.13849094510078430.139009878039360050.13896107673645020.138810276985168460.138484761118888850.137506976723670960.137424245476722720.137036532163620.136628761887550350.13594609498977660.136999756097793580.135749533772468570.135599195957183840.135654687881469730.134769335389137270.133546724915504460.133300647139549260.13292151689529420.131804808974266050.13250511884689330.13223022222518920.131500869989395140.132189452648162840.131328582763671880.131500050425529480.131530389189720150.13127571344375610.13131715357303620.13121953606605530.131567165255546570.132973909378051760.133119046688079830.133042022585868840.132886081933975220.1330711692571640.132909476757049560.132893815636634830.132403582334518430.131974667310714720.132650107145309450.132596522569656370.13218688964843750.131711095571517940.132337927818298340.133028745651245120.133561298251152040.133983626961708070.13349746167659760.133318543434143070.132710352540016170.132965281605720520.133486375212669370.133721604943275450.13397097587585450.133479952812194820.13370452821254730.133393988013267520.133121252059936520.132928937673568730.133360549807548520.133665487170219420.133773714303970340.133533462882041930.133100196719169620.133003249764442440.133533641695976260.134199872612953190.1339300423860550.134236127138137820.1346028894186020.135063141584396360.13465495407581330.134684383869171140.135006964206695560.134829372167587280.135083690285682680.134513631463050840.134731560945510860.134611204266548160.134571969509124760.134550392627716060.1346522420644760.1342366784811020.133830577135086060.13384328782558440.133730530738830570.13353644311428070.13320994377136230.132885053753852840.132535114884376530.132734194397926330.13310608267784120.133729845285415650.133911475539207460.134023711085319520.13424658775329590.134007722139358520.134045019745826720.134002298116683960.133821129798889160.13379757106304170.134155824780464170.134415522217750550.13431753218173980.1343589425086975
Epoch: 4, Training Loss: 0.1343589425086975, Training Accuracy: 0.9635499715805054, Validation Loss: 0.33304834365844727, Validation Accuracy: 0.8823999762535095
0.138626188039779660.129482820630073550.14132493734359740.119355551898479460.119123339653015140.123470388352870940.117236331105232240.115238875150680540.11045036464929580.109127864241600040.116549871861934660.11333914846181870.109378233551979060.1117505282163620.108976125717163090.106975771486759190.108974345028400420.111024983227252960.10749356448650360.107304908335208890.105954498052597050.108777113258838650.10814412683248520.106443494558334350.10750154405832290.107125811278820040.108034074306488040.108352698385715480.111646808683872220.115101113915443420.11395698785781860.115685805678367610.116041742265224460.1136057972908020.114769406616687770.113888606429100040.1139085516333580.113616794347763060.116950765252113340.11820524930953980.117338530719280240.116837441921234130.116178601980209350.115491800010204320.114106580615043640.113675452768802640.11342898011207580.115152835845947270.115072466433048250.11491055786609650.114733181893825530.115987524390220640.116764821112155910.117483362555503850.118111290037631990.117252126336097720.117294587194919590.117442347109317780.11714219301939010.116664789617061610.116965994238853450.116405524313449860.11631049215793610.11689563095569610.116972066462039950.117400258779525760.11704653501510620.117685921490192410.116720132529735570.11671955883502960.116251029074192050.115978203713893890.116358846426010130.116069294512271880.116914898157119750.116148583590984340.115939699113368990.115420289337635040.11472937464714050.114764094352722170.115002021193504330.114788860082626340.114194683730602260.113734550774097440.113618560135364530.114109359681606290.114364884793758390.114779472351074220.114670976996421810.114728324115276340.114335939288139340.114652015268802640.114893935620784760.114795148372650150.114521160721778870.114736311137676240.114921785891056060.115587338805198670.115772634744644170.116630993783473970.116959184408187870.116671442985534670.116709761321544650.117281049489974980.11699373275041580.116484224796295170.116243265569210050.116536475718021390.116910591721534730.116260878741741180.116269387304782870.116966426372528080.117206081748008730.116922736167907710.116790503263473510.11706444621086120.117221057415008540.116621285676956180.11656913906335830.116236709058284760.11589148640632630.115784451365470890.116405934095382690.115949966013431550.116050288081169130.116120554506778720.11634705215692520.116532981395721440.116373665630817410.116413496434688570.116361893713474270.1164197176694870.11611186712980270.115595303475856780.115936651825904850.11571031808853150.115680798888206480.115665778517723080.115687899291515350.115875683724880220.115373209118843080.115098923444747920.114594362676143650.114856921136379240.1148962602019310.114590726792812350.11420475691556930.114493370056152340.114694699645042420.115387156605720520.115289144217967990.115198500454425810.114900276064872740.114414237439632420.113939434289932250.113889388740062710.11378572881221771
Epoch: 5, Training Loss: 0.11378572881221771, Training Accuracy: 0.9714000225067139, Validation Loss: 0.3689364790916443, Validation Accuracy: 0.878000020980835

Training finished.
Final Training Loss: 0.11378572881221771, Final Training Accuracy: 0.9714000225067139, Final Validation Loss: 0.3689364790916443, Final Validation Accuracy: 0.878000020980835
Time taken: 407.7994158267975
