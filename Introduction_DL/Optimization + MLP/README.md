## Advanced Inro in DL and Optimization

[Link](https://drive.google.com/file/d/10OE1BJdqzC3hiFpGNFuIMCmE3McpMJui/view?usp=sharing) to the presentation

The following topics were covered in the lecture:
- Perceptron
- Forward and Backward Propagation with Examples
- Activation Functions
- Derivatives in NN. Graph
- Classification and Regression Metrics
- Optimizers (SGD, Momentum + Nesterov, AdaGrad, RMSProp, ADAM)
- Learning Rate
- Data Normalization
- Cross-Validation
- Weights Initialization (Calibrated Random Numbers, Xavier, He (or Kaiming))
- Batch Normalization
- Hyperparameter Search
- Overfitting
- Regularization (L1, L2, Dropout)
- Data Augmentation

**Further readings and materials**

1) [Vladislav Goncharenko (MLOps in Russian)](https://youtube.com/playlist?list=PLJR10EXrBaAuJzCa9HKmLRdUpgajnh1g7&si=9WRkIRQ6ZnA7AEtd)
2) The team we are inspired by in our work [girafe.ai](https://github.com/girafe-ai)